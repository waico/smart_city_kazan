{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackaton_02.12.2021_yolo5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWBF71ULTwbD"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import io\n",
        "import numpy as np\n",
        "import ast\n",
        "import cv2\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import shutil as sh\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, trange\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LflmYz4IT-oN",
        "outputId": "89b3f92c-9872-4685-c08a-751451186a5c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW0WCgoxUAFl"
      },
      "source": [
        "# path = '/content/drive/MyDrive/hackaton_02.12./trash/'\n",
        "# new_path = '/content/drive/MyDrive/hackaton_02.12./train_trash/'\n",
        "# for dir in os.listdir(path):\n",
        "#   for file in os.listdir(path+dir):\n",
        "#     #print(path + dir + '_' + file.lower())\n",
        "#     shutil.copy(path + dir + '/' + file , new_path + dir + '_' + file.lower() )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuzB3DCfUACA",
        "outputId": "88c24593-9f2f-4277-9f15-1f03ba233bc2"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5 \n",
        "!mv yolov5/* ./"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10237, done.\u001b[K\n",
            "remote: Total 10237 (delta 0), reused 0 (delta 0), pack-reused 10237\u001b[K\n",
            "Receiving objects: 100% (10237/10237), 10.40 MiB | 19.79 MiB/s, done.\n",
            "Resolving deltas: 100% (7107/7107), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TG4VuDkUAAC"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2YQNFkBT_5F"
      },
      "source": [
        "new_path = '/content/drive/MyDrive/hackaton_02.12./train_trash/'\n",
        "DIR_TRAIN= new_path\n",
        "\n",
        "dfs = list()\n",
        "\n",
        "for filename in os.listdir(new_path):\n",
        "  if '.txt' in filename.lower():\n",
        "      df = pd.read_csv(new_path + filename, sep=\" \", header=None).rename({0:'class_label',1 : 'x_c',2 : 'y_c',3 : 'w',4 : 'h'}, axis=1)\n",
        "      df['filename'] = filename.lower().replace('.txt', '.png')\n",
        "      dfs.append(df)\n",
        "\n",
        "train_df = pd.concat(dfs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnq6ZpYPT_y-",
        "outputId": "cd4e48ab-8d2c-491b-e05c-b85dac9bbe92"
      },
      "source": [
        "index = list(set(train_df['filename']))\n",
        "len(index)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyX-E54nr4q5",
        "outputId": "171c7254-bff6-4b42-ed39-4b60cb7d1ce4"
      },
      "source": [
        "if True:\n",
        "    for fold in [0]:\n",
        "        val_index = index[len(index)*fold//5:len(index)*(fold+1)//10]\n",
        "        for name,mini in tqdm(train_df.groupby('filename')):\n",
        "            if name in val_index:\n",
        "                path2save = 'val_garb/'\n",
        "            else:\n",
        "                path2save = 'train_garb/'\n",
        "            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
        "                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
        "            with open('convertor/fold{}/labels/'.format(fold)+path2save+ name.split('.')[0] +\".txt\", 'w+') as f:\n",
        "                row = mini[['class_label','x_c','y_c','w','h']].astype(float).values\n",
        "\n",
        "                # row = row/1024\n",
        "                \n",
        "                row = row.astype(str)\n",
        "                for j in range(len(row)):\n",
        "                    text = ' '.join(row[j])\n",
        "                    f.write(text)\n",
        "                    f.write(\"\\n\")\n",
        "            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
        "                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
        "                \n",
        "            sh.copy(f\"{DIR_TRAIN}/{name}\", 'convertor/fold{}/images/{}/{}'.format(fold,path2save,name))   "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 600/600 [05:25<00:00,  1.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9o-ZLbWr4iU",
        "outputId": "aaecc2b6-dc3f-4a51-b9c9-e23f45c6a6f0"
      },
      "source": [
        "%%writefile data.yaml\n",
        "\n",
        "train: /content/convertor/fold0/images/train_garb/\n",
        "val: /content/convertor/fold0/images/val_garb/\n",
        "\n",
        "nc: 2\n",
        "\n",
        "names: ['Пустой','Переполнен']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W72Rn3YEr4aB",
        "outputId": "29730afa-cafc-45c6-b0b8-e936f22076df"
      },
      "source": [
        "!python train.py --img 640 --batch 4 --epochs 10 --data data.yaml --cfg models/yolov5x.yaml --name yolov5x_fold0 --weights yolov5x.pt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=models/yolov5x.yaml, data=data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=yolov5x_fold0, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "YOLOv5 🚀 2021-12-2 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 166M/166M [00:01<00:00, 99.0MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     47103  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model Summary: 567 layers, 86224543 parameters, 86224543 gradients, 204.2 GFLOPs\n",
            "\n",
            "Transferred 738/745 items from yolov5x.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 123 weight, 126 weight (no decay), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/convertor/fold0/labels/train_garb' images and labels...540 found, 0 missing, 0 empty, 0 corrupted: 100% 540/540 [00:16<00:00, 32.12it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/convertor/fold0/images/train_garb/1_24-11-2021_11-43-15_am.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/convertor/fold0/labels/train_garb.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/convertor/fold0/labels/val_garb' images and labels...60 found, 0 missing, 0 empty, 0 corrupted: 100% 60/60 [00:01<00:00, 32.79it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/convertor/fold0/labels/val_garb.cache\n",
            "Plotting labels to runs/train/yolov5x_fold0/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.85 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5x_fold0\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/9     4.54G    0.1036   0.04738   0.02576        21       640: 100% 135/135 [08:51<00:00,  3.94s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:10<00:00,  1.30s/it]\n",
            "                 all         60        183      0.228      0.334      0.172     0.0471\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/9     4.71G   0.07818    0.0393    0.0214        17       640: 100% 135/135 [08:42<00:00,  3.87s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:10<00:00,  1.26s/it]\n",
            "                 all         60        183      0.268      0.524      0.205     0.0561\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/9     4.71G   0.07302   0.02925   0.02014        37       640: 100% 135/135 [08:37<00:00,  3.84s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:10<00:00,  1.25s/it]\n",
            "                 all         60        183       0.19      0.618      0.237     0.0518\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       3/9     4.71G   0.07078   0.02539   0.02027        20       640: 100% 135/135 [08:37<00:00,  3.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.25s/it]\n",
            "                 all         60        183      0.428      0.595       0.42      0.109\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       4/9     4.71G   0.06498   0.02402   0.01936        39       640: 100% 135/135 [08:37<00:00,  3.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.25s/it]\n",
            "                 all         60        183      0.248      0.671       0.37     0.0887\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       5/9     4.71G   0.06286   0.02177   0.01775        27       640: 100% 135/135 [08:36<00:00,  3.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.24s/it]\n",
            "                 all         60        183      0.623        0.8       0.79       0.38\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       6/9     4.71G   0.05914   0.02069   0.01711        17       640: 100% 135/135 [08:36<00:00,  3.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.25s/it]\n",
            "                 all         60        183      0.596      0.834      0.764      0.334\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       7/9     4.71G   0.05359   0.01975   0.01425        24       640: 100% 135/135 [08:34<00:00,  3.81s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.24s/it]\n",
            "                 all         60        183      0.704      0.866       0.89      0.478\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       8/9     4.71G   0.04951    0.0187    0.0128        23       640: 100% 135/135 [08:31<00:00,  3.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.24s/it]\n",
            "                 all         60        183      0.837      0.889      0.929      0.498\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       9/9     4.71G   0.04038   0.01743   0.01094        20       640: 100% 135/135 [08:36<00:00,  3.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.25s/it]\n",
            "                 all         60        183      0.886      0.943      0.964      0.651\n",
            "\n",
            "10 epochs completed in 1.481 hours.\n",
            "Optimizer stripped from runs/train/yolov5x_fold0/weights/last.pt, 173.1MB\n",
            "Optimizer stripped from runs/train/yolov5x_fold0/weights/best.pt, 173.1MB\n",
            "\n",
            "Validating runs/train/yolov5x_fold0/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 444 layers, 86180143 parameters, 0 gradients, 204.0 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 8/8 [00:11<00:00,  1.38s/it]\n",
            "                 all         60        183      0.886      0.942      0.964      0.651\n",
            "              Пустой         60        127      0.929      0.922       0.98      0.688\n",
            "          Переполнен         60         56      0.843      0.962      0.947      0.613\n",
            "Results saved to \u001b[1mruns/train/yolov5x_fold0\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovKR6gRr4Rd"
      },
      "source": [
        "!cp -r '/content/runs'  '/content/drive/MyDrive/hackaton_02.12./yolo5_all_content/'\n",
        "#!cp '/content/runs/train/yolov5x_fold0/weights/best.pt'  '/content/drive/MyDrive/hackaton_02.12./weights/best.pt'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5pZvxvNEqnq"
      },
      "source": [
        "# !cp -r '/content/models'  '/content/drive/MyDrive/hackaton_02.12./yolo5_all_content/'\n",
        "# !cp -r '/content/convertor'  '/content/drive/MyDrive/hackaton_02.12./yolo5_all_content/'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7D1vjIer4JH"
      },
      "source": [
        "!python ./detect.py --weights '/content/runs/train/yolov5x_fold0/weights/best.pt' --img 640 --conf 0.5 --source './convertor/fold0/images/val_garb/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5twSGo8uT_sq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2lgscTbT_oj"
      },
      "source": [
        "import PIL\n",
        "draw_dir = '/content/runs/detect/exp/'\n",
        "\n",
        "plt.figure(figsize=(50,25))\n",
        "rows = 4\n",
        "files = os.listdir(draw_dir)\n",
        "\n",
        "for num, x in enumerate(files):\n",
        "    plt.subplot(rows,4,num+1)\n",
        "    plt.title(x.split('.')[0])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(plt.imread(draw_dir+x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sejALwPT_mL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48qKgrRlT_kB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npZbEKGQT_h6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BL6vN63T_f7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dckjLf1BT_d0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjZsJUAqT_by"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH6TyQnhT_Z0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCNkkGWyT_X6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdHE8LdvT_WD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}