{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackaton_02.12.2021_yolo5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWBF71ULTwbD"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import io\n",
        "import numpy as np\n",
        "import ast\n",
        "import cv2\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import shutil as sh\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, trange\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LflmYz4IT-oN",
        "outputId": "00f647fd-5a39-409e-bdf6-af00f91b0f39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2VXavEcfjem"
      },
      "source": [
        "new_path = '/content/drive/MyDrive/hackaton_02.12./train_trash/'\n",
        "DIR_TRAIN= new_path"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxGepaUbfhJv"
      },
      "source": [
        "#Get lower case\n",
        "path = new_path\n",
        "for file in os.listdir(path):\n",
        "    os.rename(path + file, path + file.lower())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW0WCgoxUAFl"
      },
      "source": [
        "# path = '/content/drive/MyDrive/hackaton_02.12./trash/'\n",
        "# new_path = '/content/drive/MyDrive/hackaton_02.12./train_trash/'\n",
        "# for dir in os.listdir(path):\n",
        "#   for file in os.listdir(path+dir):\n",
        "#     #print(path + dir + '_' + file.lower())\n",
        "#     shutil.copy(path + dir + '/' + file , new_path + dir + '_' + file.lower() )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuzB3DCfUACA",
        "outputId": "2363100d-a0ae-413e-e60c-10cb12e1dcd5"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5 \n",
        "!mv yolov5/* ./\n",
        "!pip install -r requirements.txt\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.1.1)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2YQNFkBT_5F",
        "outputId": "5a2c9de6-7447-4329-d339-7c97d596d066"
      },
      "source": [
        "dfs = list()\n",
        "\n",
        "for filename in tqdm(os.listdir(new_path)):\n",
        "  if '.txt' in filename.lower():\n",
        "      try:\n",
        "        df = pd.read_csv(new_path + filename, sep=\" \", header=None).rename({0:'class_label',1 : 'x_c',2 : 'y_c',3 : 'w',4 : 'h'}, axis=1)\n",
        "\n",
        "        if 'tire_' in filename.lower():\n",
        "          df['filename'] = filename.lower().replace('.txt', '.jpg')\n",
        "          df['class_label'] = df['class_label'].apply(lambda x: 2)\n",
        "\n",
        "        elif 'fire' in filename.lower():\n",
        "          df['filename'] = filename.lower().replace('.txt', '.jpg')\n",
        "          df['class_label'] = df['class_label'].apply(lambda x: 3)\n",
        "        else:\n",
        "          df['filename'] = filename.lower().replace('.txt', '.png')\n",
        "\n",
        "        dfs.append(df)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "train_df = pd.concat(dfs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1508/1508 [02:46<00:00,  9.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "F1vFAbqpdwms",
        "outputId": "9c9efd1e-e883-44b5-caf0-caf082eaf5ec"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_label</th>\n",
              "      <th>x_c</th>\n",
              "      <th>y_c</th>\n",
              "      <th>w</th>\n",
              "      <th>h</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.424854</td>\n",
              "      <td>0.543120</td>\n",
              "      <td>0.041385</td>\n",
              "      <td>0.072500</td>\n",
              "      <td>10_23-11-2021_07-40-57_pm.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.523878</td>\n",
              "      <td>0.540782</td>\n",
              "      <td>0.036339</td>\n",
              "      <td>0.080750</td>\n",
              "      <td>10_23-11-2021_07-40-57_pm.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.465635</td>\n",
              "      <td>0.544556</td>\n",
              "      <td>0.044615</td>\n",
              "      <td>0.074648</td>\n",
              "      <td>10_23-11-2021_07-40-57_pm.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.516310</td>\n",
              "      <td>0.541125</td>\n",
              "      <td>0.038214</td>\n",
              "      <td>0.080750</td>\n",
              "      <td>10_25-11-2021_08-26-22_pm.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.473427</td>\n",
              "      <td>0.541852</td>\n",
              "      <td>0.039281</td>\n",
              "      <td>0.074648</td>\n",
              "      <td>10_25-11-2021_08-26-22_pm.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class_label       x_c  ...         h                       filename\n",
              "0            0  0.424854  ...  0.072500  10_23-11-2021_07-40-57_pm.png\n",
              "1            0  0.523878  ...  0.080750  10_23-11-2021_07-40-57_pm.png\n",
              "2            0  0.465635  ...  0.074648  10_23-11-2021_07-40-57_pm.png\n",
              "0            0  0.516310  ...  0.080750  10_25-11-2021_08-26-22_pm.png\n",
              "1            0  0.473427  ...  0.074648  10_25-11-2021_08-26-22_pm.png\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnq6ZpYPT_y-",
        "outputId": "03b088d3-b47d-4797-d587-2a3ecf515357"
      },
      "source": [
        "index = list(set(train_df['filename']))\n",
        "len(index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "754"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WED3lxr1YuuN"
      },
      "source": [
        "#!rm -rf /content/convertor"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyX-E54nr4q5",
        "outputId": "27b4c1b4-31e0-469d-c829-8ea5b7bf541e"
      },
      "source": [
        "if True:\n",
        "    for fold in [0]:\n",
        "        val_index = index[len(index)*fold//5:len(index)*(fold+1)//10]\n",
        "        for name,mini in tqdm(train_df.groupby('filename')):\n",
        "            if name in val_index:\n",
        "                path2save = 'val_garb/'\n",
        "            else:\n",
        "                path2save = 'train_garb/'\n",
        "            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
        "                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
        "            with open('convertor/fold{}/labels/'.format(fold)+path2save+ name.split('.')[0] +\".txt\", 'w+') as f:\n",
        "                row = mini[['class_label','x_c','y_c','w','h']].astype(float).values\n",
        "\n",
        "                # row = row/1024\n",
        "                \n",
        "                row = row.astype(str)\n",
        "                for j in range(len(row)):\n",
        "                    text = ' '.join(row[j])\n",
        "                    f.write(text)\n",
        "                    f.write(\"\\n\")\n",
        "            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
        "                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
        "                \n",
        "            sh.copy(f\"{DIR_TRAIN}/{name}\", 'convertor/fold{}/images/{}/{}'.format(fold,path2save,name))   "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 754/754 [05:12<00:00,  2.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9o-ZLbWr4iU",
        "outputId": "346e2224-8bac-412e-c65f-df57a4968166"
      },
      "source": [
        "%%writefile data.yaml\n",
        "\n",
        "train: /content/convertor/fold0/images/train_garb/\n",
        "val: /content/convertor/fold0/images/val_garb/\n",
        "\n",
        "nc: 4\n",
        "\n",
        "names: ['ÐŸÑƒÑÑ‚Ð¾Ð¹','ÐŸÐµÑ€ÐµÐ¿Ð¾Ð»Ð½ÐµÐ½', 'ÐœÑƒÑÐ¾Ñ€', 'ÐžÐ³Ð¾Ð½ÑŒ']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W72Rn3YEr4aB",
        "outputId": "234996cc-6c23-4d39-eb5a-9974c1d11993"
      },
      "source": [
        "!python train.py --img 640 --batch 4 --epochs 20 --data data.yaml --cfg models/yolov5x.yaml --name yolov5x_fold0 --weights yolov5x.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=models/yolov5x.yaml, data=data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=20, batch_size=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=yolov5x_fold0, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "YOLOv5 ðŸš€ 2021-12-3 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 166M/166M [00:01<00:00, 100MB/s] \n",
            "\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     60561  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model Summary: 567 layers, 86238001 parameters, 86238001 gradients, 204.2 GFLOPs\n",
            "\n",
            "Transferred 738/745 items from yolov5x.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 123 weight, 126 weight (no decay), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/convertor/fold0/labels/train_garb' images and labels...679 found, 0 missing, 0 empty, 0 corrupted: 100% 679/679 [00:16<00:00, 40.76it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/convertor/fold0/images/train_garb/1_24-11-2021_11-43-15_am.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/convertor/fold0/labels/train_garb.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/convertor/fold0/labels/val_garb' images and labels...75 found, 0 missing, 0 empty, 0 corrupted: 100% 75/75 [00:01<00:00, 37.85it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/convertor/fold0/labels/val_garb.cache\n",
            "Plotting labels to runs/train/yolov5x_fold0/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.69 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5x_fold0\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/19     4.54G    0.1132   0.03887   0.04531        12       640:  27% 46/170 [03:03<07:59,  3.87s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovKR6gRr4Rd"
      },
      "source": [
        "!cp -r '/content/runs'  '/content/drive/MyDrive/hackaton_02.12./yolo5_all_content/'\n",
        "#!cp '/content/runs/train/yolov5x_fold0/weights/best.pt'  '/content/drive/MyDrive/hackaton_02.12./weights/best.pt'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5pZvxvNEqnq"
      },
      "source": [
        "# !cp -r '/content/models'  '/content/drive/MyDrive/hackaton_02.12./yolo5_all_content/'\n",
        "# !cp -r '/content/convertor'  '/content/drive/MyDrive/hackaton_02.12./yolo5_all_content/'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7D1vjIer4JH"
      },
      "source": [
        "!python ./detect.py --weights '/content/runs/train/yolov5x_fold0/weights/best.pt' --img 640 --conf 0.5 --source './convertor/fold0/images/val_garb/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5twSGo8uT_sq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2lgscTbT_oj"
      },
      "source": [
        "import PIL\n",
        "draw_dir = '/content/runs/detect/exp/'\n",
        "\n",
        "plt.figure(figsize=(50,25))\n",
        "rows = 4\n",
        "files = os.listdir(draw_dir)\n",
        "\n",
        "for num, x in enumerate(files):\n",
        "    plt.subplot(rows,4,num+1)\n",
        "    plt.title(x.split('.')[0])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(plt.imread(draw_dir+x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sejALwPT_mL"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48qKgrRlT_kB"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npZbEKGQT_h6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BL6vN63T_f7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dckjLf1BT_d0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjZsJUAqT_by"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH6TyQnhT_Z0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCNkkGWyT_X6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdHE8LdvT_WD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}