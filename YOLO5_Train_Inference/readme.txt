1. Для быстрого запуска inference модели в ноутбуке YOLO_Inference.ipynb желательно использовать GoogleColab
2. Cкачать веса по ссылке с GoogleDrive и передать их как параметр в --weights (по аналогии с примером в ноутбуке, желательно полный путь)
3. Для предикта в параметре --source указать директорию с файлами или конкретный файл (по аналогии с примером в ноутбуке, желательно полный путь)
4. Путь до результата с предиктом будет в логе запуска - "Results saved to", или указать вручную.

5. Ссылка на директорию с весами моделей, best_2.pt и best_4.pt соответственно
https://drive.google.com/drive/folders/1GngMurVoAZ-4tjBJWCziYvHtdw25lfC7?usp=sharing
